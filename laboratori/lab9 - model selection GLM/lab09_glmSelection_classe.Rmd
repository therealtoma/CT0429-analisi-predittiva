---
title: "Lab 09 - more about GLMs"
output: 
  html_document: 
    toc: yes
---


# Model selection per i GLMs - Binomial 

I dati nel file `SAheart.csv` sono stati raccolti in uno studio osservazionale retrospettivo su un campione di uomini residenti in una zona ad alto rischio di malattie cardiache a Città del Capo in Sud Africa. La variabile `chd` (coronary heart disease), che useremo come variabile risposta, è una variabile binaria (codifcata con valori 0/1) che indica se un individuo presenta malattie alle coronarie. Le altre variabili presenti nel dataset sono: 

* sbp: systolic blood pressure
* tobacco: cumulative tobacco (kg)
* ldl: low densiity lipoprotein cholesterol
* adiposity
* famhist: family history of heart disease (Present, Absent)
* typea: type-A behavior
* obesity
* alcohol: current alcohol consumption
* age: age at onset

[Qui](https://hastie.su.domains/ElemStatLearn/) potete trovare più informazioni sul dataset. 



```{r, eval=TRUE}
SAheart <- read.table("../data/SAheart.csv",sep=",",head=TRUE)
```

Desideriamo costruire un modello che predica la probabilità di avere una malattia alle coronarie dati i valori delle altre caratteristiche. Possiamo fare una prima analisi esplorativa per vedere le caratteristiche delle diverse variabili esplicative nei gruppi di persone malate e non malate (escludiamo dai grafici le variabili categoriali):  

```{r}
par(mfrow=c(2,2))
for(j in 1:4) plot(jitter(SAheart$chd, amount = 0.2)~SAheart[,j], main = names(SAheart)[j])
```

```{r}
par(mfrow=c(2,2))
for(j in 6:9) plot(jitter(SAheart$chd, amount = 0.2)~SAheart[,j], main = names(SAheart)[j])
```


Per `famhist`, che è una variabile categoriale, possiamo utilizzare un cosiddetto mosaicplot: 


```{r}
table(SAheart$famhist, SAheart$chd)
mosaicplot(table(SAheart$famhist, SAheart$chd))
```

Possiamo costruire un primo modello predittivo utilizzando `ldl`, i livelli di colesterolo, come variabile esplicativa:

```{r}
par(mfrow=c(1,1))
chd_mod_ldl <- glm(chd ~ ldl, data = SAheart, family = binomial)
summary(chd_mod_ldl)
plot(jitter(chd, factor = 0.1) ~ ldl, data = SAheart, pch = 20, 
ylab = "Probability of CHD", xlab = "Low Density Lipoprotein Cholesterol")
grid()
lines(sort(SAheart$ldl),
  predict(chd_mod_ldl, data.frame(ldl = sort(SAheart$ldl)), type = "response"), 
  col = "dodgerblue", lty = 2, lwd = 2)
```

Al crescere dei valori di colesterolo cresce la probabilità che l'individuo sia malato. Possiamo derivare degli intervalli di confidenza per l'effetto di `ldl` sul log-odd di essere malato con `conf.int`: 

```{r}
confint.default(chd_mod_ldl,level=0.95, parm = "ldl")
## based on asymptotic normal distribution
coef(chd_mod_ldl)[2] + summary(chd_mod_ldl)$coef[2,2] * qnorm(c(0.025,0.975))
```

Invece che usare un solo predittore potremmo invece usare tutte le informazioni a nostra disposizione per predirre `chd`: 

```{r}
chd_mod_additive <- glm(chd ~ ., data = SAheart,  family = binomial)
summary(chd_mod_additive)
```

E chiederci se c'è una differenza in termini di bontà di adattamento del modello tra i due modelli, o in altre parole, andare a verificare se aver usato molti predittori in più ha avuto un effetto notevole sulla devianza/verosimiglianza: 

```{r}
chd_mod_ldl$deviance
chd_mod_additive$deviance
```

C'è una certa differenza nella devianza residua dei modelli: è una differenza importante? Possiamo usare il likelihood ratio test per verificare la cosa. Il test verifica l'ipotesi nulla 

\[H_0: \beta_{\texttt{sbp}} = \beta_{\texttt{tobacco}} = \beta_{\texttt{adiposity}} = \beta_{\texttt{famhist}} = \beta_{\texttt{typea}} = \beta_{\texttt{obesity}} = \beta_{\texttt{alcohol}} = \beta_{\texttt{age}} = 0 \]

contro l'alternativa 

\[H_1: \text{any } \beta_{\texttt{sbp}} \text{ or } \beta_{\texttt{tobacco}}  \text{ or }  \beta_{\texttt{adiposity}}  \text{ or }  \beta_{\texttt{famhist}}  \text{ or }  \beta_{\texttt{typea}}  \text{ or }  \beta_{\texttt{obesity}}  \text{ or } \beta_{\texttt{alcohol}}  \text{ or } \beta_{\texttt{age}} \neq 0 \]



# Model selection per GLMs - Poisson 

Ci concentriamo ora sul dataset `hcrabs` in cui la variabile di interesse è il numero di satelliti attorno ad un granchio femmina. Desideriamo individuare i predittori che possono risultare utili nello spiegare la variabilità della variabile risposta. Innanzitutto leggiamo il dataset ed esploriamo le relazioni tra predittori e risposta: 


```{r}
hcrabs <- read.csv("hcrabs.csv", header = TRUE)
plot(hcrabs)
```


`Spine` e `Col` sono dei fattori ordinati: 

```{r}
hcrabs$Spine <- factor(hcrabs$Spine, levels = c("NoneOK", "OneOK", "BothOK"))
hcrabs$Col <- factor(hcrabs$Col, levels = c("LM", "M", "DM", "D"))
```

`Sat` (la variabile risposta) sembra essere legata a `Width` e `Wt`, le quali però sono anche legate tra loro. Le altre variabili nel dataset sono variabili categoriali Inoltre ci sono alcune variabili categoriali per cui lo scatterplot non facilita la comprensione delle relazioni tra i predittori ma che sembrano avere forse qualche effetto su `Sat`: 

```{r}
par(mfrow=c(1,2))
plot(Sat~Col, data =hcrabs)
plot(Sat~Spine, data =hcrabs)
```

# Valutare un modello tramite i residui 

Per 30 isole delle Galàpagos, abbiamo informazioni sul numero di speci di piante in ogni isola e il numero di queste che sono ritenute endemiche (questa variabile non sarà utilizzata e può essere cancellata). Abbiamo anche alcune informaizoni sulle caratteristiche geografiche dell'isola:

```{r}
data(gala, package = "faraway")
# help(gala, package = "faraway") 
gala <- gala[,-2]
head(gala)
plot(gala)
```

Potremmo pensare di adattare un modello lineare per stimare il numero di specie nell'isola:

```{r}
modl <- lm(Species ~ . , gala) 
```

e controllare la bontà di adattamento con un grafico *residual vs. fitted*: 

```{r}
plot(modl, 1)
```
