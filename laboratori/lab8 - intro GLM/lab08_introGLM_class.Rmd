---
title: "Lab 08 - introduzione ai GLMs in R"
author: "Ilaria Prosdocimi"
output: 
  html_document: 
    toc: yes
---


Il dataset `patents.txt` contiene informazioni raccolte dall'ufficio brevetti dell'UE su alcune caratteristiche dei brevetti, tra cui il numero di citazioni, se è stata presentata un'opposizione al brevetto, l'anno in cui il brevetto è stato depositato e l'informazione se il brevetto è nel settore bio-farmaceutico. (Il dataset è stato derivato dal dataset sulle patenti utilizzato nel libro [*Regression* di Fahrmeir et al.](https://www.uni-goettingen.de/de/regression+-+models%2c+methods+and+applications/550514.html). 

```{r}
dat <- read.table("../data/patents.txt")
dat$biopharm <- factor(dat$biopharm)
summary(dat)
```


# La modellazione di dati binari 

Ci concentriamo ora sulla variabile `opposed`, un indicatore che ha valore "opposed" e "not-opposed". Diamo un'occhiata alle caratteristiche della variabile: 


```{r}
summary(dat$opposed)
table(dat$opposed)
```

vediamo che nella maggior parte dei casi il brevetto è non opposto.  Vogliamo valutare se c'è un effetto dell'anno in cui il brevetto è stato presentato sulla probabilità che venga presentata un'opposizione al brevetto: 

```{r,eval=FALSE}
plot(opposed~year, data = dat)
## this doesn't work 
```


```{r,eval=TRUE}
plot((opposed == "opposed") ~year, data = dat)
```

Non si capisce granché, possiamo "sparpagliare" i valori di 0/1 con la funzione `jitter`


```{r,eval=FALSE}
plot(jitter(opposed == "opposed") ~year, data = dat)
## this doesn't work
```


```{r}
plot(jitter(ifelse(opposed == "opposed", 1,0), amount = 0.1) ~year, data = dat)
```

```{r}
plot(jitter(ifelse(opposed == "opposed", 1,0), amount = 0.1) ~
       jitter(year, amount = 0.2), data = dat)
```

Non un effetto così chiaro. Per stimare come varia la probabilità che ci sia un'opposizione ad un brevetto possiamo usare un glm: come specificare un glm in R? Abbiamo bisogno dei seguenti elementi 

* la distribuzione che si assume per la variabile risposta $Y$ (in questo caso una binomiale, in particolare un Bernoulli, cioè una binomiale in cui vi è un solo "tentativo"): $Y \sim Bin(1, p(x))$, con $\mu(x) = E[Y|X=x] = p(x)$
* la funzione legame tra $\mu(x)$ e il predittore lineare $\eta(x)$: usiamo in questo caso il legame canonico, cioè la trasformazione logistica: $logit(\mu(x)) = \beta_1 + \beta_1 x$
* la specificazione del predittore lineare: in questo modello usiamo un solo predittore, `year` 


La funzione che possiamo usare in R è la funzione `glm` dove è possibile specificare la distribuzione che si assume per la variabile risposta usando l'argomento `family`: 

```{r, eval=FALSE}
fit_bin <- glm(opposed ~ year, data = dat, family = binomial)
## this doesn't work 
```

Con gli standard errros possiamo fare dell'inferenza, ad esempio costruire intervalli di confidenza, o "a mano" o usando la funzione `confint.default`: 


```{r}
confint.default(fit_bin)
confint.default(fit_bin, parm = "yearSince1979")
coef(fit_bin)[2] + qnorm(c(0.025,0.975))*sqrt(vcov(fit_bin)[2,2])
```

Nota: a differenza di quanto fatto per il modelli lineari, per costruire l'intervallo di confidenza usiamo un normale (e non una T di Student) dato che stiamo utilizzando il fatto che le stime dei coefficienti di regressione nei GLM sono ottenute tramite massima verosimiglianza per cui possiamo sfruttare il fatto che per gli stimatori di massima verosimiglianza si ha una distribuzione approssimativamente normale. Di conseguenza l'intervallo di confidenza è approssimato e l'approssimazione sarà tanto migliore quanto più è grande il campione.

Cerchiamo adesso di capire un po' meglio la stima ottenuta del modello  


Come possiamo interpretare i coefficienti? [Video che spiega come non sia banale la cosa!](https://twitter.com/ChelseaParlett/status/1304436259926896640).  

```{r}
nd <- data.frame(yearSince1979 = c(1, 2, 17, 18))
# the linear predictor fit 
```

Il coefficiente $\beta_1$ rappresenta l'effetto (su scale logaritmica) del predittore sull'odds ratio: un coefficiente positivo indica che al crescere di X cresce la probabilità che $Y =1$. Tuttavia quanto sia forte questo effetto dipende dal valore di X, non è costante. Possiamo visualizzare l'effetto che ha il predittore sul valore atteso della variabile risposta:  



In questo esempio la stima della probabilità è piuttosto lineare nell'intervallo di tempo osservato. Se pensassimo di estendere (di molto) l'intervallo in cui valutiamo la funzione troveremmo la classica forma sigmoide della regressione logistica: 

```{r}
# binomial()$linkfun
# binomial()$linkinv
par(pch = 16, bty = "l", mfrow=c(1,1))
nd <- data.frame(yearSince1979 = seq(-100, 100, by = 2))
### we can not plot the inverse-link transformed data
### they take values -inf or + inf 
plot(nd$yearSince1979,
     predict(fit_bin, newdata = nd, type="response"),
     type="l",  main = "The estimated probability")
## one can alsi directly use the binomial()$linkinv function 
lines(nd$yearSince1979,
     binomial()$linkinv(fit_bin$coef[1] + fit_bin$coef[2]*nd$yearSince1979),
     type="l",  col = 2)
```

Per una applicazione vagamente sensata non avrebbe molto senso estrapolare così avanti o indietro nel tempo: questo grafico ha solo lo scopo di far vedere la forma classica della regressione logistica. 

Vogliamo ora indagare se l'essere o meno un brevetto che ha a che fare con l'ambito bio-farmaceutico incide sulla probabilità che vi sia una opposizione al brevetto. Possiamo provare a dare un'occhiata ai dati


```{r}
plot(jitter(ifelse(opposed == "opposed", 1,0), amount = 0.1) ~
       jitter(year, amount = 0.2), data = dat, col = ifelse(dat$biopharm == "1", 2, 1))
```

Sembrano esserci molti punti rossi (brevetti in ambito bio-farmaceutico) per cui è stata presentata un'opposizione. 

Aggiungiamo il predittore al modello già stimato: 

```{r}
fit_bin2 <- glm(fopp ~ yearSince1979+biopharm, family = binomial, data = dat)
summary(fit_bin2)
```


Quando un brevetto ha a che fare con l'ambito bio-farmaceutico, tendono ad esserci più opposizioni. Possiamo anche verificare se vi è un'interazione tra l'anno di presentazione della richiesta e il tipo di brevetto: 

```{r}
fit_bin3 <- glm(fopp ~ yearSince1979*biopharm, family = binomial, data = dat)
summary(fit_bin3)
```

Un effetto che appare essere significativo. Possiamo visualizzare il modello stimato (anche qui estrapoliamo la funzione a dismisura per visualizzare bene le differenze): 

```{r}
# binomial()$linkfun
# binomial()$linkinv
par(pch = 16, bty = "l", mfrow=c(1,1))
nd <- data.frame(yearSince1979 = seq(-100, 100, by = 2), biopharm = 0)
plot(nd$yearSince1979,
     binomial()$linkinv(fit_bin3$coef[1] + fit_bin3$coef[2]*nd$yearSince1979 + 
                          fit_bin3$coef[3]*nd$biopharm+ fit_bin3$coef[4]*nd$biopharm*nd$yearSince1979),
     type="l",  col = 2)
nd <- data.frame(yearSince1979 = seq(-100, 100, by = 2), biopharm = 1)
lines(nd$yearSince1979,
     binomial()$linkinv(fit_bin3$coef[1] + fit_bin3$coef[2]*nd$yearSince1979 + 
                          fit_bin3$coef[3]*nd$biopharm+ fit_bin3$coef[4]*nd$biopharm*nd$yearSince1979),
     col = 4)
abline(v = range(dat$yearSince1979), col = "grey", lty = 2)
```

Per i brevetti in ambito bio-farmaceutico c'è una probabilità più alta che si registri un'opposizione e questa probabilità è diminuta in maniera meno forte rispetto agli altri ambiti. 

# Un modello per il numero di citazioni 

Ci concentriamo ora sulla variabile `ncit`, il numero di citazioni ricevute da un brevetto. Le citazioni sono in qualche modo una misura del successo di un brevetto: desideriamo verificare se i brevetti depositati recentemente hanno più successo. 
`ncit` è una variabile che misura dei conteggi: possiamo assumere che segua una distribuzione di Poisson. Diamo un'occhiata ai dati: 

```{r}
# notice we already use yearSince1979
plot(ncit~yearSince1979, data = dat) 
```

Difficile sapere quanti punti ci sono in ogni combinazione - usiamo jitter

```{r}
plot(jitter(ncit, amount = 0.2)~jitter(yearSince1979, amount = 0.2), 
     data = dat) 
```

Non un effetto chiarissimo, ma forse le citazioni di brevetti presentati di recente sono relativamente meno (hanno avuto meno tempo per essere citate). Iniziamo comunque con un modello semplice per capire come lavorare con modelli con dati di conteggio: 


```{r}
fit_pois <- glm(ncit~yearSince1979, data = dat, family = poisson)
summary(fit_pois)
```

Un effetto significativo e negativo del tempo: brevetti presentati in anni più recenti hanno meno citazioni. 

Da dove arriva la stima che facciamo, è una stima di massima verosimiglianza, sarà vero? 


In generale però nei GLM possiamo sfruttare alcune caratteristiche della verosimiglianza nelle famiglie esponenziali e la stima viene fatta tramite un algoritmo noto come Fisher scoring, che equivale a fare ripetutamente una stima basata su una minimizzazione dei quadrati pesati. Vediamo come funziona. Dovremo risolvere in maniera iterativa l'equazione: 
$$\boldsymbol{X}^\top \boldsymbol{V} \boldsymbol{X} \boldsymbol{\beta}^{(t)} = \boldsymbol{X}^\top \boldsymbol{V} \boldsymbol{z}$$
dove $\boldsymbol{V} = diag(v_{ii})$ e $\boldsymbol{z} = (z_1, \ldots, z_n)$ dipendono da $\beta^{(t)}$, e sono definiti come: 
$$v_{ii} = V_i(\boldsymbol{\beta}^{(t)})  = \left(\frac{\partial \mu_i}{\partial \eta_i}\right)^2 \frac{1}{\phi V_i}$$ 
$$z^{(t)}_i = \left. \boldsymbol{X}\boldsymbol{\beta}^{(t)} + (y_i - \mu_i^{(t)}) \frac{\partial \eta_i}{\partial \mu_i}\right\rvert_{\boldsymbol{\beta}^{(t)}}$$. 

Per il caso della Poisson con legame canonico: 

* $\phi = 1$
* $\mu_i = \exp\left\{\beta_0 + \beta_1 x\right\} = \exp\left\{\eta_i\right\}$ quindi $\frac{\partial \mu_i}{\partial \eta_i} = \exp{\eta_i}$
* $\eta_i = \log(\mu_i)$ quindi $\frac{\partial \eta_i}{\partial \mu_i} = 1/\mu_i$
* $V_i = Var(Y_i) = \mu_i = \exp\left\{\beta_0 + \beta_1 x_i\right\}$




Andiamo adesso a capire più in dettaglio che modello abbiamo stimato. Si assume che 

\[Y_i = (Y|X = x_i) \sim Pois(\lambda(yearSince1979_i)) \]
dove 
\[\lambda(yearSince1979_i) = \exp\{\beta_0 + \beta_1 yearSince1979_i \} \]
con il predittore lineare $\eta(yearSince1979_i) = \log(\lambda(yearSince1979_i))$:
\[\eta(yearSince1979_i) = \beta_0 + \beta_1 yearSince1979_i\]
Dato che $Y_i$ segue una Poisson si ha che $E[Y_i] (= Var(Y_i)) = \lambda_i$. Quindi `yearSince1979` ha un effetto sul valore atteso della distribuzione tramite la funzione legame. Due brevetti presentati in due anni distanti tra loro $c$ anni avranno come valore predetto: 

\[\lambda(x_0) = \exp\{\beta_0 + \beta_1 x_0 \} \quad \lambda(x_0 + c) = \exp\{\beta_0 + \beta_1 (x_0 + c) \}\]

e si ha che $\lambda(x_0 + c)  = \lambda(x_0) \exp\{c\}$: l'effetto della differenza di $c$ unità nella variabile esplicativa ha un effetto moltiplicativo sul valore atteso. 

Possiamo verificare la cosa usando la funzione `predict`: 

```{r}
nd <- data.frame(yearSince1979 = c(1,2, 17, 18))
# linear predictor  

# response 

# response is exp(linear predictor)

```

Per visualizzare l'effetto di una variabile esplicativa sulla variabile risposta si possono usare i predittori lineari (sulla scala logaritmica) o delle trasformazioni dei predittori lineari sulla scala della variabile risposta: 

```{r}
par(mfrow=c(1,2), pch = 16, col = "grey40")
plot(dat$yearSince1979, log(dat$ncit))
## but careful about any(dat$ncit == 0)
nd <- data.frame(yearSince1979=seq(1, 18, by=1))
lines(nd$yearSince1979, predict(fit_pois, newdata = nd),
      col = 2, lwd = 2)
plot(dat$yearSince1979, dat$ncit)
lines(nd$yearSince1979, 
      predict(fit_pois, newdata = nd, type="response"),
      col = 4, lwd = 2)
```

In questo grafico i brevetti con 0 citazioni non vengono mostrati ($log(0) = -\infty$). Per mostrare i valori pari a 0 a volte vengono mostrati con dei valori piccoli ma maggiori di 0: 

```{r}
par(mfrow=c(1,1), pch = 16, col = "grey40")
plot(dat$yearSince1979, jitter(log(pmax(dat$ncit, 0.5)),amount = 0.05)) 
# a fixed amount is not great here 
nd <- data.frame(yearSince1979=seq(1, 18, by=1))
lines(nd$yearSince1979, predict(fit_pois, newdata = nd),
      col = 2, lwd = 2)
```

E se invece guardiamo il valore sulla scale della variabile risposta? 



```{r}
# we can use poly like in linear models 
fit_pois_quad <- glm(formula = ncit ~ poly(yearSince1979,2)+biopharm+fopp, 
                     family = poisson, data = dat)
summary(fit_pois_quad)
```

Che modello abbiamo stimato? Guardiamo sia i predittori lineari che l'effetto sulla scala della variabile risposta 

```{r}
par(mfrow=c(1,2), pch = 16, col = "grey40")
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "1", fopp = "opposed")
plot(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "link"),
      col = 2, lwd = 2, type = "l")
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "1", fopp = "not-opposed")
lines(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "link"),
      col = 2, lwd = 2, lty = 2)
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "0", fopp = "opposed")
lines(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "link"),
      col = 1, lwd = 2)
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "0", fopp = "not-opposed")
lines(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "link"),
      col = 1, lwd = 2, lty = 2)
# paralle parabolas 
# on the orginal scale 
plot(dat$yearSince1979, jitter(dat$ncit, amount = 0.2), 
     ## add transparency 
     col = ifelse(dat$biopharm == "1", rgb(1,0,0,0.4),rgb(0,0,0,0.4)), 
     pch = ifelse(dat$fopp == "opposed", 16,15)) 
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "1", fopp = "opposed")
lines(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "response"),
      col = 2, lwd = 2)
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "1", fopp = "not-opposed")
lines(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "response"),
      col = 2, lwd = 2, lty = 2)
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "0", fopp = "opposed")
lines(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "response"),
      col = 1, lwd = 2)
nd <- data.frame(yearSince1979=seq(1, 18, by=1), biopharm = "0", fopp = "not-opposed")
lines(nd$yearSince1979, predict(fit_pois_quad, newdata = nd, type = "response"),
      col = 1, lwd = 2, lty = 2)
```

I brevetti in ambito bio-farmaceutico e che hanno avuto un'opposizione sono i brevetti che hanno più citazioni. 

I singoli predittori sono significativi. Il modello `fit_pois` è annidato in questo modello e possiamo quindi chiederci come confrontare modelli annidati. Usiamo l'analisi della devianza. 

## La devianza 

Nel `summary` R stampa l'informazione su devianza nulla e devianza residua, che una misura della bontà di adattamento   di un modello ai dati, in qualche modo simile alla somma dei quadrati dei residui del modello (e è anche la devizna qualcosa che si cerca di minimizzare): 

```{r}
fit_pois$deviance
fit_pois_quad$deviance
```

Modelli più complessi tendono a far diminuire la devianza. La devianza nulla è la devianza per un modello in cui non vengono usati predittori: 

```{r}
fit_pois_quad$null.deviance
glm(ncit ~1,family = poisson, data = dat)$null.deviance
```

Da dove arrivano questi numeri? La devianza è definita con: 

\[D = 2 \sum_{i=1}^{n} d_i =  \sum_{i=1}^{n}(l^{sat} -  l(\hat{\beta}))  \]

dove $l^{sat}$ è il massimo valore possibile per la log-verosimiglianza che si ottiene con $\mu^{sat} = y_i$. 

La log-verosimiglianza per il modello di Poisson è: 

\[l(\mu_i, y_i) =  y_i log \mu_i  - \mu_i \]

quindi $l^{sat} = y_i \log y_i - y_i$. Ne risulta che la devianza ha la seguente forma: 

\[D = \sum_{i=1}^{n}\left( (y_i \log y_i - y_i) - (y_i \log \hat{\mu}_i  - \hat{\mu}_i)  \right)  \]
con $\hat{\mu}_i = \exp\{ \beta_0 + \beta_1 x_{i,1} + \ldots + \beta_{p-1} x_{i, p-1} \}$

Per il modello `fit_pois`, in cui solo `yearSince1979` è inserito come predittore, deriviamo: 

```{r}
## notice the convention that when y=0, y*log(y) = 0
#fit_pois$deviance
```

Per calcolare la devianza nulla invece pensiamo che la stima per ogni punto del campione si derivi usando $\hat{\mu} = \bar{y}$:  

```{r}
# fit_pois_null <- glm(ncit ~ 1, data = dat, family = poisson)

```

Sotto certe assunzioni generali (che tipicamente sono valide per i GLM non patologici), si ha che:

\[D \sim \chi^2_{n-p} \]

Usiamo questo fatto per creare un test sulla significatività del modello (un test quindi simile al test F): vale la pena includere dei predittori o usare un modello più semplice porta comunque ad una devianza non poi così diversa? R permette di fare questo test con la funzione `anova`:

```{r}
# anova(fit_pois_null, fit_pois, test = "LRT")
```


Perché usiamo la devianza quando facciamo un Likelihood ratio test (che come dice il nome dovrebbe essere un test basato sul rapporto delle verosimiglianze?)

\[LR = 2log\frac{L(\mathcal{M_{full}})}{L(\mathcal{M_{null}})} = 2 (l(\mathcal{M_{full}}) - l(\mathcal{M_{null}})) = 2 (l(\mathcal{M_{full}}) - l(\mathcal{M_{null}}) + l^{sat} - l^{sat})  = D(M_{null}) - D(M_{full})\]


# La modellazione del numero di successi (proporzioni)  

La distribuzione binomiale che viene usata quando si specifica  `family = binomial` può essere usata non solo per dati binari ma anche per dati in cui il dato discreto che si modella è il numero di successi ($y$) su un totale di $k$ tentativi, assumendo che $Y|X=x \sim Bin(k, p(x))$. Come specificato in ?family possiamo specificare il modello per questo tipo di dati in due modi: 

* As a numerical vector with values between 0 and 1, interpreted as the proportion of successful cases (with the total number of cases given by the weights).
* As a two-column integer matrix: the first column gives the number of successes and the second the number of failures.

Come primo esempio deriviamo dal dataset `patents` l'informazione di quanti brevetti sono stati depositati e di quanti hanno avuto un'opposizione per ogni anno. Da questa informazione (molto più sintetica di quella disponibile in prima istanza), possiamo modellare la proporzione dei brevetti per cui vi è un'opposizione: 

```{r}
# dat <- dat[order(dat$year),]
byYear <- data.frame(year = tapply(dat$year, factor(dat$year), unique), 
                     numopp = tapply(dat$numopp, factor(dat$year), sum), 
                     tpat = tapply(dat$numopp, factor(dat$year), length)) 
byYear$n_notopp <- byYear$tpat - byYear$numopp
byYear$propOpp <- byYear$numopp/byYear$tpat
head(byYear)
##first specification
fit_t1_bin <- glm(cbind(numopp, n_notopp)~year, family = binomial, data = byYear)             
summary(fit_t1_bin)
## second specification
fit_t2_bin <- glm(propOpp~year, family = binomial, weights = tpat, data = byYear)             
summary(fit_t2_bin)
summary(fit_bin)
```

In questo caso notiamo che la stima che otteniamo è identica alla stima ottenuta quando usavamo l'informazione individuale di ogni brevetto (il modello `fit_bin`): questo è vero solo perché `year`, la variabile esplicativa, ha lo stesso valore per tutte le osservazioni di un anno. Non potremmo per esempio usando questi dati più "compatti" valutare l'effetto che ha la variabile `biopharm` sulla probabilità che venga registrata un'opposizione al brevetto. In generale però ci sono delle somiglianze nella modellazione di dati binari e nei dati che hanno a che fare con proporzioni.


Vediamo un altro esempio molto famoso che ha avuto conseguenze molto rilevanti legate al disastro dello [https://it.wikipedia.org/wiki/Disastro_dello_Space_Shuttle_Challenger](Shuttle Challenger). L'esplosione del razzo fu imputata al fatto che delle guarnizioni di sicurezza (O-rings) ebbero un guasto causando una perdita nel serbatoio e l'esplosione. Ex-post la causa del guasto agli O-rings fu identificata nella bassa temperatura a cui venne effettuato il lancio. La sera prima del lancio, sebbene le previsioni meteo indicavano che la temperatura il giorno successivo sarebbe stata bassa (tra i 25 e i 27 gradi Fahrenheit), si decise di andare avanti con il lancio sulla base delle informazioni disponibili sui lanci precedenti in cui erano stati riscontrati danni agli O-rings, in cui non si era rilevato un effetto della temperatura sulla probabilità di riscontrare danni agli O-rings. I dati sono contenuti nel dataset `shuttles1`: ogni shuttle aveva un totale di 6 O-rings e la variabile `Damaged` indica quanti degli O-rings siano risultati danneggiati mentre `Temp` indica la temperatura a cui erano avvenuti i lanci. 

```{r}
shuttles1 <- read.table("shuttles1.txt", header = TRUE)
plot(shuttles1, ylim = c(0,3))
shuttles1$prop <- shuttles1$Damaged / 6
shuttles1$NotDamaged <- 6 - shuttles1$Damaged
plot(shuttles1$Temp, shuttles1$prop, ylim = c(0,1))
```


Stimiamo la probabilità che avvenga un danneggiamento agli O-rings in funzione della temperatura: 

```{r}
# option with matrix
fit_shuttle1_mat <- glm(cbind(Damaged, NotDamaged) ~ Temp, data = shuttles1, family = binomial)
summary(fit_shuttle1_mat)
# options with proportion 
fit_shuttle1_prop <- glm(prop ~ Temp, data = shuttles1, weights = rep(6, nrow(shuttles1)), family = binomial)
summary(fit_shuttle1_prop)
```


La stima è equivalente e si trova un effetto non significativo della temperatura: 


Tuttavia nell'analisi manca l'informazione sui lanci in cui non erano stati registrati errori: le informazioni su tutti i lanci precedenti all'incidente sono contentui nel dataset `shuttles2`: 

```{r}
shuttles2 <- read.table("shuttles2.txt", header = TRUE)
plot(shuttles2, ylim = c(0,3))
shuttles2$prop <- shuttles2$Damaged / 6
shuttles2$NotDamaged <- 6 - shuttles2$Damaged
plot(shuttles2$Temp, shuttles2$prop, ylim = c(0,1))
```


Stimiamo un modello in cui le informazioni di tutti i lanci sono utilizzate: 



La probabilità di un problema con gli O-rings in un lancio a temperature molto basse viene stimata molto alta, ma stiamo estrapolando molto al di fuori delle temperature per cui sono già stati fatti lanci: la stima sarà molto imprecisa, ma forse era alta abbastanza da motivare uno stop al lancio del razzo. 


# Verifica della teoria tramite simulazione 

Abbiamo detto che l'inferenza nei modelli lineari generalizzati si basa sulla distribuzione approssimata di $\hat{\beta}$. Dato che $\hat{\beta}$ viene stimato tramite il metodo della massima verosimiglianza si ha che il seguente risutalto approssimato:  

\[\hat{\beta} \sim N(\beta, (X^TVX)^{-1})\]

Andiamo a verificare tramite uno studio di simulazione se questo risultato sia valido (e nel caso andiamo a vedere se ci sono situazioni in cui è più o meno robusto). 

Andiamo quindi a generare dei dati usando un modello noto per poi andare a vedere cosa succede quando stimiamo il modello usando i dati generati dal modello noto. Dobbiamo generare dati da una distribuzione che appartiene alla famiglia esponenziale e usare una funzione legame per legare il valore atteso della distribuzione al predittore lineare. Iniziamo con un modello in cui la variabile risposta segue una distribuzione di Poisson il cui valore atteso dipende da una variabile esplicativa (che prendiamo essere un campione da una uniforme in (-4.5, 4.5)) e due parametri ($\beta_0$, $\beta_1$) (che prendiamo avere valore (3,0.05) ): 

```{r}
n <- 60 ## what happens if this decreases? 
x_vals <- sort(runif(n, -4.5, 4.5))
beta_vals <- c(3,0.05)
Xmat <- cbind(rep(1, n), x_vals)
set.seed(76)
y_sim <- rpois(n, poisson()$linkinv(Xmat %*% beta_vals))
plot(Xmat[,2], y_sim)
```

I dati mostrano una relazione tra predittore e risposta: possiamo stimare questa relazione: 

```{r}
fit_sim <- glm(y_sim ~ x_vals, family = poisson)
fit_sim$coefficients
## compared to 
beta_vals
```   

La stima dei parametri è abbastanza vicina aio veri valori dei parametri usati per generare i dati e la funzione stimata infatti assomiglia abbastanza alla vera relazione tra predittore e risposta: 
```{r}
par(mfrow=c(1,2))
plot(x_vals, Xmat %*% beta_vals, type="l", main = "Linear predictor")
lines(x_vals, Xmat %*% fit_sim$coefficients, col = 4)
plot(x_vals, exp(Xmat %*% beta_vals), type="l",  main = "Response")
lines(x_vals, exp(Xmat %*% fit_sim$coefficients), col = 4)
```

Ripetiamo quest'esperimento 50 volte: 

```{r}
# sim_fit_coef <- function(n, X, pars){}
```
